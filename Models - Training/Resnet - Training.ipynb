{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020905,
     "end_time": "2023-04-06T23:10:06.813408",
     "exception": false,
     "start_time": "2023-04-06T23:10:06.792503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 align=center> Facial Expression Recognition</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020089,
     "end_time": "2023-04-06T23:10:06.853597",
     "exception": false,
     "start_time": "2023-04-06T23:10:06.833508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020161,
     "end_time": "2023-04-06T23:10:06.896444",
     "exception": false,
     "start_time": "2023-04-06T23:10:06.876283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:10:06.945739Z",
     "iopub.status.busy": "2023-04-06T23:10:06.944904Z",
     "iopub.status.idle": "2023-04-06T23:10:27.980182Z",
     "shell.execute_reply": "2023-04-06T23:10:27.979486Z",
     "shell.execute_reply.started": "2023-04-06T05:19:52.696231Z"
    },
    "id": "wvGxjjeV-9Ls",
    "papermill": {
     "duration": 21.063624,
     "end_time": "2023-04-06T23:10:27.980332",
     "exception": false,
     "start_time": "2023-04-06T23:10:06.916708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016697,
     "end_time": "2023-04-06T23:10:28.015266",
     "exception": false,
     "start_time": "2023-04-06T23:10:27.998569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting total number of images of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:10:28.058054Z",
     "iopub.status.busy": "2023-04-06T23:10:28.057432Z",
     "iopub.status.idle": "2023-04-06T23:10:30.528494Z",
     "shell.execute_reply": "2023-04-06T23:10:30.527940Z",
     "shell.execute_reply.started": "2023-04-06T07:11:22.610850Z"
    },
    "id": "TalL_1Qr-9Qz",
    "outputId": "f5fb9b05-976a-4979-ea23-33c3d87efb94",
    "papermill": {
     "duration": 2.49568,
     "end_time": "2023-04-06T23:10:30.528606",
     "exception": false,
     "start_time": "2023-04-06T23:10:28.032926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for expression in os.listdir(\"../fer2013-kaggle/train\"):\n",
    "    print(str(len(os.listdir(\"../fer2013-kaggle/train/\" + expression))) + \" \" + expression + \" images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018533,
     "end_time": "2023-04-06T23:10:30.565852",
     "exception": false,
     "start_time": "2023-04-06T23:10:30.547319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate Training and Validation Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x\n",
    "\n",
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "    # dataset: Data path\n",
    "def get_data(dataset):\n",
    "    data = pd.read_csv(dataset)\n",
    "    pixels = data['Paths'].tolist()\n",
    "    images = np.empty((len(data), img_size, img_size, 3))\n",
    "    i = 0\n",
    "\n",
    "    for pixel_path in pixels:\n",
    "        if i%5000 ==0:\n",
    "            print(i,\" done\")\n",
    "        single_image = cv2.imread('../'+pixel_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #single_image = np.asarray(single_image).reshape(48, 48) # Dimension: 48x48\n",
    "        single_image = resize(single_image, (img_size, img_size), order = 3, mode = 'constant') # Dimension: 139x139x3 (Bicubic)\n",
    "        ret = np.empty((img_size, img_size, 3))  \n",
    "        ret[:, :, 0] = single_image\n",
    "        ret[:, :, 1] = single_image\n",
    "        ret[:, :, 2] = single_image\n",
    "        images[i, :, :, :] = ret\n",
    "        i += 1\n",
    "    \n",
    "    images = preprocess_input(images)\n",
    "    labels = to_categorical(data['Expression'])\n",
    "\n",
    "    return images, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "train_data_x, train_data_y  = get_data('../fer2013-kaggle/Train.csv')\n",
    "val_data  = get_data('../fer2013-kaggle/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_preprocessor = ImageDataGenerator(\n",
    "        rescale = 1 / 255.,\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,                                        \n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    rescale = 1 / 255.,\n",
    ")\n",
    "\n",
    "train_generator = train_preprocessor.flow(\n",
    "    train_data_x,\n",
    "    train_data_y,\n",
    "    batch_size  = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018247,
     "end_time": "2023-04-06T23:11:04.559328",
     "exception": false,
     "start_time": "2023-04-06T23:11:04.541081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018674,
     "end_time": "2023-04-06T23:11:04.596524",
     "exception": false,
     "start_time": "2023-04-06T23:11:04.577850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50V2(weights='imagenet', \n",
    "                                        input_shape=(img_size, img_size, 3),\n",
    "                                        include_top= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable = True\n",
    "\n",
    "for layer in resnet.layers[:-20]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02376,
     "end_time": "2023-04-06T23:11:08.894082",
     "exception": false,
     "start_time": "2023-04-06T23:11:08.870322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "                      resnet,\n",
    "                      Dropout(.25),\n",
    "                      BatchNormalization(),\n",
    "                      Flatten(),\n",
    "                      Dense(64, activation='relu'),\n",
    "                      BatchNormalization(),\n",
    "                      Dropout(.5),\n",
    "                      Dense(7,activation='softmax')\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060653,
     "end_time": "2023-04-06T23:11:08.977835",
     "exception": false,
     "start_time": "2023-04-06T23:11:08.917182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:11:15.849599Z",
     "iopub.status.busy": "2023-04-06T23:11:15.846909Z",
     "iopub.status.idle": "2023-04-06T23:21:12.661766Z",
     "shell.execute_reply": "2023-04-06T23:21:12.660899Z",
     "shell.execute_reply.started": "2023-04-06T07:58:01.386981Z"
    },
    "papermill": {
     "duration": 596.848186,
     "end_time": "2023-04-06T23:21:12.661914",
     "exception": false,
     "start_time": "2023-04-06T23:11:15.813728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                            \"../Model weights/Resnet_model.h5\", monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1\n",
    "                            )\n",
    "\n",
    "# Create Early Stopping Callback to monitor the accuracy\n",
    "Early_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 5, restore_best_weights = True)\n",
    "\n",
    "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning\n",
    "Reducing_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "callbacks = [Early_Stopping, Reducing_LR, checkpoint]\n",
    "\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "       x = train_data_x,\n",
    "    y=train_data_y,\n",
    "    steps_per_epoch=len(train_data_x) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = val_data,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.195225,
     "end_time": "2023-04-06T23:21:15.020717",
     "exception": false,
     "start_time": "2023-04-06T23:21:13.825492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.15639,
     "end_time": "2023-04-06T23:21:22.114079",
     "exception": false,
     "start_time": "2023-04-06T23:21:20.957689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class for loading model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:21:24.566632Z",
     "iopub.status.busy": "2023-04-06T23:21:24.564805Z",
     "iopub.status.idle": "2023-04-06T23:21:24.567262Z",
     "shell.execute_reply": "2023-04-06T23:21:24.567689Z",
     "shell.execute_reply.started": "2023-04-06T08:17:59.910226Z"
    },
    "papermill": {
     "duration": 1.24321,
     "end_time": "2023-04-06T23:21:24.567816",
     "exception": false,
     "start_time": "2023-04-06T23:21:23.324606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class FacialExpressionModel(object):\n",
    "\n",
    "    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\n",
    "                    \"Fear\", \"Happy\",\n",
    "                    \"Neutral\", \"Sad\",\n",
    "                    \"Surprise\"]\n",
    "\n",
    "    def __init__(self, model_file):\n",
    "        # load model from JSON file\n",
    "        self.loaded_model = load_model(model_file)\n",
    "\n",
    "    def predict_emotion(self, img):\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]\n",
    "    \n",
    "    def predict(self, img):\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "        return self.preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.20046,
     "end_time": "2023-04-06T23:21:26.951529",
     "exception": false,
     "start_time": "2023-04-06T23:21:25.751069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting frames and doing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:21:29.318805Z",
     "iopub.status.busy": "2023-04-06T23:21:29.318210Z",
     "iopub.status.idle": "2023-04-06T23:21:29.821169Z",
     "shell.execute_reply": "2023-04-06T23:21:29.820162Z",
     "shell.execute_reply.started": "2023-04-06T08:18:06.370257Z"
    },
    "papermill": {
     "duration": 1.702757,
     "end_time": "2023-04-06T23:21:29.821302",
     "exception": false,
     "start_time": "2023-04-06T23:21:28.118545",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "facec = cv2.CascadeClassifier('../haarcascade_frontalface_default.xml')\n",
    "model_facial_Exp = FacialExpressionModel(\"../Model weights/RESNET_model.h5\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "class VideoCamera(object):\n",
    "    def __init__(self):\n",
    "        self.video = cv2.VideoCapture(0)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "\n",
    "    # returns camera frames along with bounding boxes and predictions\n",
    "    def get_frame(self):\n",
    "        _, fr = self.video.read()\n",
    "        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            fc = gray_fr[y:y+h, x:x+w]\n",
    "            single_image = resize(single_image, (img_size, img_size), order = 3, mode = 'constant') # Dimension: 139x139x3 (Bicubic)\n",
    "            ret = np.empty((img_size, img_size, 3))  \n",
    "            ret[:, :, 0] = single_image\n",
    "            ret[:, :, 1] = single_image\n",
    "            ret[:, :, 2] = single_image\n",
    "            pred = model_facial_Exp.predict_emotion(ret[np.newaxis, :, :])\n",
    "\n",
    "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
    "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.202897,
     "end_time": "2023-04-06T23:21:32.208880",
     "exception": false,
     "start_time": "2023-04-06T23:21:31.005983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function for showing output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:21:34.697756Z",
     "iopub.status.busy": "2023-04-06T23:21:34.696860Z",
     "iopub.status.idle": "2023-04-06T23:21:34.699448Z",
     "shell.execute_reply": "2023-04-06T23:21:34.699842Z",
     "shell.execute_reply.started": "2023-04-06T08:18:09.833679Z"
    },
    "papermill": {
     "duration": 1.286111,
     "end_time": "2023-04-06T23:21:34.699989",
     "exception": false,
     "start_time": "2023-04-06T23:21:33.413878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen(camera):\n",
    "    while True:\n",
    "        frame = camera.get_frame()\n",
    "        cv2.imshow('Facial Expression Recognization',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the true labels and predicted labels for the validation set\n",
    "validation_labels = np.argmax(val_data[1], axis=1)\n",
    "validation_pred_probs = model.predict(val_data[0])\n",
    "validation_pred_labels = np.argmax(validation_pred_probs, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(validation_labels, validation_pred_labels)\n",
    "class_names = [\"Angry\", \"Disgust\",\n",
    "                    \"Fear\", \"Happy\",\n",
    "                    \"Neutral\", \"Sad\",\n",
    "                    \"Surprise\"]#list(train_generator.class_indices.keys())\n",
    "sns.set()\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='YlGnBu', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(validation_labels, validation_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "duration": 699.255025,
   "end_time": "2023-04-06T23:21:42.238224",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-06T23:10:02.983199",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
